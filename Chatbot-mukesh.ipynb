{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73086ebb-b315-485f-a799-f667ab757d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\athar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8be473e1-c832-4fb5-a38c-11fa83cab67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN Model\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) \n",
    "        self.l2 = nn.Linear(hidden_size, hidden_size) \n",
    "        self.l3 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l3(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3eec3185-d05b-4b35-98c5-d467809fe70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\athar\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\athar\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\athar\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\athar\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\athar\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\athar\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\athar\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\athar\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "264e0254-ffb5-42eb-9f3b-2d654b8fc7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/intents3.json', 'r') as f:\n",
    "    intents = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7a55cd5-2ce2-48e9-8734-c80f1c43dadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    \"\"\"\n",
    "    split sentence into array of words/tokens\n",
    "    a token can be a word or punctuation character, or number\n",
    "    \"\"\"\n",
    "    return nltk.word_tokenize(sentence)\n",
    "\n",
    "\n",
    "def stem(word):\n",
    "    \"\"\"\n",
    "    stemming = find the root form of the word\n",
    "    examples:\n",
    "    words = [\"organize\", \"organizes\", \"organizing\"]\n",
    "    words = [stem(w) for w in words]\n",
    "    -> [\"organ\", \"organ\", \"organ\"]\n",
    "    \"\"\"\n",
    "    return stemmer.stem(word.lower())\n",
    "\n",
    "\n",
    "def bag_of_words(tokenized_sentence, words):\n",
    "    \"\"\"\n",
    "    return bag of words array:\n",
    "    1 for each known word that exists in the sentence, 0 otherwise\n",
    "    example:\n",
    "    sentence = [\"hello\", \"how\", \"are\", \"you\"]\n",
    "    words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]\n",
    "    bag   = [  0 ,    1 ,    0 ,   1 ,    0 ,    0 ,      0]\n",
    "    \"\"\"\n",
    "    # stem each word\n",
    "    sentence_words = [stem(word) for word in tokenized_sentence]\n",
    "    # initialize bag with 0 for each word\n",
    "    bag = np.zeros(len(words), dtype=np.float32)\n",
    "    for idx, w in enumerate(words):\n",
    "        if w in sentence_words: \n",
    "            bag[idx] = 1\n",
    "\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aff6d94f-d140-49ad-9c8e-ad1457813973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113 patterns\n",
      "31 tags: ['Identity', 'activity', 'age', 'appreciate', 'contact', 'covid19', 'cricket', 'datetime', 'exclaim', 'goodbye', 'google', 'greeting', 'greetreply', 'haha', 'inspire', 'insult', 'jokes', 'karan', 'news', 'nicetty', 'no', 'noanswer', 'options', 'programmer', 'riddle', 'song', 'suggest', 'thanks', 'timer', 'weather', 'whatsup']\n",
      "121 unique stemmed words: [\"'m\", \"'s\", ',', '10', '19', 'a', 'age', 'am', 'anyon', 'are', 'ask', 'awesom', 'bad', 'bbye', 'be', 'best', 'bye', 'can', 'contact', 'could', 'covid', 'creator', 'cricket', 'current', 'date', 'day', 'design', 'develop', 'do', 'dumb', 'fine', 'for', 'funni', 'get', 'good', 'goodby', 'googl', 'great', 'haha', 'he', 'hello', 'help', 'hey', 'hi', 'hola', 'hot', 'how', 'i', 'idiot', 'india', 'inspir', 'internet', 'is', 'it', 'joke', 'karan', 'know', 'later', 'latest', 'laugh', 'lmao', 'lol', 'lost', 'made', 'make', 'malik', 'match', 'me', 'motiv', 'namast', 'news', 'next', 'nice', 'no', 'nope', 'offer', 'ok', 'old', 'program', 'programm', 'provid', 'question', 'riddl', 'rofl', 'score', 'search', 'see', 'set', 'shut', 'song', 'suggest', 'sup', 'support', 'talk', 'tell', 'temperatur', 'ten', 'thank', 'that', 'the', 'there', 'till', 'time', 'timer', 'to', 'today', 'top', 'up', 'upto', 'useless', 'wa', 'wazzup', 'weather', 'were', 'what', 'when', 'who', 'yeah', 'yo', 'you', 'your']\n"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "tags = []\n",
    "xy = []\n",
    "# loop through each sentence in our intents patterns\n",
    "for intent in intents['intents']:\n",
    "    tag = intent['tag']\n",
    "    # add to tag list\n",
    "    tags.append(tag)\n",
    "    for pattern in intent['patterns']:\n",
    "        # tokenize each word in the sentence\n",
    "        w = tokenize(pattern)\n",
    "        # add to our words list\n",
    "        all_words.extend(w)\n",
    "        # add to xy pair\n",
    "        xy.append((w, tag))\n",
    "\n",
    "# stem and lower each word\n",
    "ignore_words = ['?', '.', '!']\n",
    "all_words = [stem(w) for w in all_words if w not in ignore_words]\n",
    "# remove duplicates and sort\n",
    "all_words = sorted(set(all_words))\n",
    "tags = sorted(set(tags))\n",
    "\n",
    "print(len(xy), \"patterns\")\n",
    "print(len(tags), \"tags:\", tags)\n",
    "print(len(all_words), \"unique stemmed words:\", all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ffecbc16-9bc5-4bde-bf32-5a4e9589f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_words = []\n",
    "# tags = []\n",
    "# xy = []\n",
    "# # loop through each intent in our intents list\n",
    "# for intent in intents['intents']:\n",
    "#     tag = intent['intent']\n",
    "#     # add to tag list\n",
    "#     tags.append(tag)\n",
    "#     for text in intent['text']:\n",
    "#         # tokenize each word in the text\n",
    "#         w = tokenize(text)\n",
    "#         # add to our words list\n",
    "#         all_words.extend(w)\n",
    "#         # add to xy pair\n",
    "#         xy.append((w, tag))\n",
    "\n",
    "# # stem and lower each word\n",
    "# ignore_words = ['?', '.', '!']\n",
    "# all_words = [stem(w) for w in all_words if w not in ignore_words]\n",
    "# # remove duplicates and sort\n",
    "# all_words = sorted(set(all_words))\n",
    "# tags = sorted(set(tags))\n",
    "\n",
    "# print(len(xy), \"patterns\")\n",
    "# print(len(tags), \"intents:\", tags)\n",
    "# print(len(all_words), \"unique stemmed words:\", all_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f66f4ae5-26fd-47b1-9bfa-36b0aac84079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training data\n",
    "X_train = []\n",
    "y_train = []\n",
    "for (pattern_sentence, tag) in xy:\n",
    "    # X: bag of words for each pattern_sentence\n",
    "    bag = bag_of_words(pattern_sentence, all_words)\n",
    "    X_train.append(bag)\n",
    "    # y: PyTorch CrossEntropyLoss needs only class labels, not one-hot\n",
    "    label = tags.index(tag)\n",
    "    y_train.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "343953e7-8029-45e5-ab19-8d33a375a4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 31\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters \n",
    "num_epochs = 1000\n",
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "input_size = len(X_train[0])\n",
    "hidden_size = 8\n",
    "output_size = len(tags)\n",
    "print(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ce4fd910-f5ff-485b-b241-819ec2f83df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da1a3a78-ec52-4181-a0c2-d9eb916727b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.n_samples = len(X_train)\n",
    "        self.x_data = X_train\n",
    "        self.y_data = y_train\n",
    "\n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f5797f2-dac5-4004-ab11-52a48e881832",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChatDataset()\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7dad1c7-6a87-4fda-8279-76389211fb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 2.5061\n",
      "Epoch [200/1000], Loss: 0.0549\n",
      "Epoch [300/1000], Loss: 0.0143\n",
      "Epoch [400/1000], Loss: 0.0106\n",
      "Epoch [500/1000], Loss: 0.0106\n",
      "Epoch [600/1000], Loss: 0.0001\n",
      "Epoch [700/1000], Loss: 0.0019\n",
      "Epoch [800/1000], Loss: 0.0000\n",
      "Epoch [900/1000], Loss: 0.0001\n",
      "Epoch [1000/1000], Loss: 0.0000\n",
      "final loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for (words, labels) in train_loader:\n",
    "        words = words.to(device)\n",
    "        labels = labels.to(dtype=torch.long).to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(words)\n",
    "        # if y would be one-hot, we must apply\n",
    "        # labels = torch.max(labels, 1)[1]\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "print(f'final loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2672c0b9-1e8a-4bb9-a2eb-559944732228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete. file saved to data.pth\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "\"model_state\": model.state_dict(),\n",
    "\"input_size\": input_size,\n",
    "\"hidden_size\": hidden_size,\n",
    "\"output_size\": output_size,\n",
    "\"all_words\": all_words,\n",
    "\"tags\": tags\n",
    "}\n",
    "\n",
    "FILE = \"data.pth\"\n",
    "torch.save(data, FILE)\n",
    "\n",
    "print(f'training complete. file saved to {FILE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bd33168-cfaa-4436-8b09-54fe94a821db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's chat! (type 'quit' to exit)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mukesh: Hello\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  how are you\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mukesh: I do not understand...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  why were you made\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mukesh: I do not understand...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mukesh: Hi there, how can I help?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mukesh: Hello\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  ask me a riddle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mukesh:  What will you actually find at the end of every rainbow?.....The letter 'w'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  why\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mukesh: I do not understand...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hmm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mukesh: I do not understand...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  you are useless\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mukesh: Please mail your suggestions to ted.thedlbot.suggestions@gmail.com. Thank you for helping me improve!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  how old are you\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mukesh: I was made in 2020, if that's what you are asking!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  riddle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mukesh:  How can a girl go 25 days without sleep?.....She sleeps and night!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  quit\n"
     ]
    }
   ],
   "source": [
    "# # CHATBOT\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "# FILE = \"data.pth\"\n",
    "# data = torch.load(FILE)\n",
    "\n",
    "# input_size = data[\"input_size\"]\n",
    "# hidden_size = data[\"hidden_size\"]\n",
    "# output_size = data[\"output_size\"]\n",
    "# all_words = data['all_words']\n",
    "# tags = data['tags']\n",
    "# model_state = data[\"model_state\"]\n",
    "\n",
    "# model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
    "# model.load_state_dict(model_state)\n",
    "# model.eval()\n",
    "\n",
    "# bot_name = \"Mukesh\"\n",
    "# print(\"Let's chat! (type 'quit' to exit)\")\n",
    "# while True:\n",
    "#     # sentence = \"do you use credit cards?\"\n",
    "#     sentence = input(\"You: \")\n",
    "#     if sentence == \"quit\":\n",
    "#         break\n",
    "\n",
    "#     sentence = tokenize(sentence)\n",
    "#     X = bag_of_words(sentence, all_words)\n",
    "#     X = X.reshape(1, X.shape[0])\n",
    "#     X = torch.from_numpy(X).to(device)\n",
    "\n",
    "#     output = model(X)\n",
    "#     _, predicted = torch.max(output, dim=1)\n",
    "\n",
    "#     tag = tags[predicted.item()]\n",
    "\n",
    "#     probs = torch.softmax(output, dim=1)\n",
    "#     prob = probs[0][predicted.item()]\n",
    "#     if prob.item() > 0.75:\n",
    "#         for intent in intents['intents']:\n",
    "#             if tag == intent[\"tag\"]:\n",
    "#                 print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n",
    "#     else:\n",
    "#         print(f\"{bot_name}: I do not understand...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aad01f35-f67d-4c90-b7a1-6d128ebf52f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak now!\n",
      "You said: hi mukesh\n",
      "Mukesh: Hello\n",
      "Speak now!\n",
      "Sorry, I didn't catch that. Please try again.\n",
      "Mukesh: I'm sorry, I don't understand.\n",
      "Speak now!\n",
      "You said: why were you made\n",
      "Mukesh: I'm sorry, I don't understand.\n",
      "Speak now!\n",
      "You said: ask me a question\n",
      "Mukesh: What two things can you never eat for breakfast?.....Lunch and Dinner!\n",
      "Speak now!\n",
      "You said: kuwait\n",
      "Mukesh: I'm sorry, I don't understand.\n",
      "Speak now!\n",
      "You said: kuwait\n",
      "Mukesh: I'm sorry, I don't understand.\n",
      "Speak now!\n",
      "You said: quit\n"
     ]
    }
   ],
   "source": [
    "# VIRTUAL ASSISTANT\n",
    "\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "FILE = \"data.pth\"\n",
    "data = torch.load(FILE)\n",
    "\n",
    "input_size = data[\"input_size\"]\n",
    "hidden_size = data[\"hidden_size\"]\n",
    "output_size = data[\"output_size\"]\n",
    "all_words = data['all_words']\n",
    "tags = data['tags']\n",
    "model_state = data[\"model_state\"]\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
    "model.load_state_dict(model_state)\n",
    "model.eval()\n",
    "\n",
    "bot_name = \"Mukesh\"\n",
    "\n",
    "def listen():\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Speak now!\")\n",
    "        audio = r.listen(source)\n",
    "    try:\n",
    "        command = r.recognize_google(audio).lower()\n",
    "        print(f\"You said: {command}\")\n",
    "        return command\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sorry, I didn't catch that. Please try again.\")\n",
    "        return \"\"\n",
    "    except sr.RequestError:\n",
    "        print(\"Sorry, I'm having trouble connecting to the speech recognition service.\")\n",
    "        return \"\"\n",
    "\n",
    "def speak(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "speak(f\"Hi, I'm {bot_name}. How can I help you today?\")\n",
    "while True:\n",
    "    command = listen()\n",
    "    if command == \"quit\":\n",
    "        speak(\"Goodbye!\")\n",
    "        break\n",
    "    sentence = tokenize(command)\n",
    "    X = bag_of_words(sentence, all_words)\n",
    "    X = X.reshape(1, X.shape[0])\n",
    "    X = torch.from_numpy(X).to(device)\n",
    "\n",
    "    output = model(X)\n",
    "    _, predicted = torch.max(output, dim=1)\n",
    "\n",
    "    tag = tags[predicted.item()]\n",
    "\n",
    "    probs = torch.softmax(output, dim=1)\n",
    "    prob = probs[0][predicted.item()]\n",
    "    if prob.item() > 0.75:\n",
    "        for intent in intents['intents']:\n",
    "            if tag == intent[\"tag\"]:\n",
    "                response = random.choice(intent['responses'])\n",
    "                speak(f\"{bot_name}: {response}\")\n",
    "                print(f\"{bot_name}: {response}\")\n",
    "    else:\n",
    "        speak(f\"{bot_name}: I'm sorry, I don't understand.\")\n",
    "        print(f\"{bot_name}: I'm sorry, I don't understand.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b0dc0ec-c00a-4083-a026-bb260cdfa40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyAudio\n",
      "  Using cached PyAudio-0.2.13-cp39-cp39-win_amd64.whl (164 kB)\n",
      "Installing collected packages: PyAudio\n",
      "Successfully installed PyAudio-0.2.13\n"
     ]
    }
   ],
   "source": [
    "!pip install PyAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed9bbf3-6bd5-460c-b292-078f5237aac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
